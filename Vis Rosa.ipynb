{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This Python script asks user via GUI to upload a .CSV file, reads the data, and plots and prints the translated data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'customtkinter'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mnetworkx\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mnx\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mcollections\u001b[39;00m \u001b[39mimport\u001b[39;00m defaultdict\n\u001b[0;32m----> 5\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mcustomtkinter\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mmatplotlib\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpyplot\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mplt\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mmatplotlib\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mfigure\u001b[39;00m \u001b[39mimport\u001b[39;00m Figure\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'customtkinter'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "from collections import defaultdict\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.figure import Figure\n",
    "from matplotlib.backends.backend_tkagg import FigureCanvasTkAgg\n",
    "from tkinter import Tk, filedialog, Button, Text, Scrollbar, Frame\n",
    "import matplotlib.cm as cm\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from scipy.cluster import hierarchy\n",
    "\n",
    "def process_csv():\n",
    "    file_path = filedialog.askopenfilename(filetypes=[(\"CSV files\", \"*.csv\")])\n",
    "    df = pd.read_csv(file_path, header=None)\n",
    "    items_in_csv = df.iloc[:, 0].unique()\n",
    "    timegap_dict, total_shoppers = calculate_timegap(df)\n",
    "    \n",
    "    pair_list = sorted(list(set(pair for pair in timegap_dict.keys())))\n",
    "    item_list = sorted(list(set(item for pair in timegap_dict.keys() for item in pair)))\n",
    "\n",
    "    k_optimal = silhoutte_score(timegap_dict)\n",
    "    #k_optimal = scree_plot(timegap_dict)\n",
    "    cluster_labels, linkage_matrix = perform_hierarchical_clustering(timegap_dict, num_clusters=k_optimal)\n",
    "    plot_dendrogram(linkage_matrix)\n",
    "\n",
    "    for widget in right_frame.winfo_children():\n",
    "        widget.destroy()\n",
    "\n",
    "    items_graph(timegap_dict, items_in_csv)\n",
    "    clustered_graph_frame = Frame(right_frame)\n",
    "    clustered_graph_frame.pack(side='left', padx=10, pady=10, fill='both', expand=True)\n",
    "    clustered_items_graph(timegap_dict, items_in_csv, cluster_labels, clustered_graph_frame)\n",
    "\n",
    "    total_unique_items = len(item_list)\n",
    "    \n",
    "    item_cluster_dict = {}\n",
    "    for i, item in enumerate(item_list):\n",
    "        item_cluster_dict[item] = cluster_labels[i] + 1  # Assign the cluster number (starting from 1)\n",
    "\n",
    "    cluster_counts = {cluster: 0 for cluster in range(1, k_optimal + 1)}\n",
    "    for item, cluster in item_cluster_dict.items():\n",
    "        cluster_counts[cluster] += 1\n",
    "    \n",
    "    #for GUI\n",
    "    item_list_text.config(state='normal')\n",
    "    item_list_text.delete(1.0, 'end')\n",
    "    item_list_text.insert('end', \"List of Unique Items:\\n\")\n",
    "    for i, item in enumerate(item_list):\n",
    "        item_list_text.insert('end', f\"{i + 1}. {item} - Cluster: {item_cluster_dict[item]}\\n\")\n",
    "    item_list_text.config(state='disabled')\n",
    "\n",
    "    timegap_text.config(state='normal')\n",
    "    timegap_text.delete(1.0, 'end')\n",
    "    timegap_text.insert('end', \"Normalized Timegaps:\\n\")\n",
    "    for i, (pair, timegaps) in enumerate(timegap_dict.items()):\n",
    "        avg = sum(timegaps) / len(timegaps)\n",
    "        item_x, item_x_plus_1 = pair\n",
    "        timegap_text.insert('end', f\"Pair {i + 1}: {avg:.2f} (Items: {item_x} -> {item_x_plus_1})\\n\")\n",
    "    timegap_text.config(state='disabled')\n",
    "    \n",
    "    dataset_info_text.config(state='normal')\n",
    "    dataset_info_text.delete(1.0, 'end')\n",
    "    dataset_info_text.insert('end', f\"Total Unique Items: {total_unique_items}\\n\\n\")\n",
    "    dataset_info_text.insert('end', f\"Total Shoppers: {total_shoppers}\\n\\n\")\n",
    "    for cluster, count in cluster_counts.items():\n",
    "        dataset_info_text.insert('end', f\"Cluster {cluster} - Items: {count}\\n\")\n",
    "    dataset_info_text.config(state='disabled')\n",
    "    \n",
    "    sorted_items = sorted(item_cluster_dict.items(), key=lambda x: x[1])\n",
    "    clusters = list(set(cluster for item, cluster in sorted_items))\n",
    "    clustered_data_text.config(state='normal')\n",
    "    clustered_data_text.delete(1.0, 'end')\n",
    "    clustered_data_text.insert('end', \"Clustered Items:\\n\")\n",
    "    for cluster in clusters:\n",
    "        clustered_data_text.insert('end', f\"Cluster {cluster}:\\n\")\n",
    "        cluster_items = [item for item, c in sorted_items if c == cluster]\n",
    "        for i, item in enumerate(cluster_items):\n",
    "            clustered_data_text.insert('end', f\"{i + 1}. {item} - Cluster: {item_cluster_dict[item]}\\n\")\n",
    "        clustered_data_text.insert('end', \"\\n\")\n",
    "    clustered_data_text.config(state='disabled')\n",
    "\n",
    "def calculate_timegap(df):\n",
    "    data = defaultdict(list)\n",
    "    current_list = None\n",
    "    current_data = []\n",
    "    total_shoppers = 0\n",
    "\n",
    "    for index1 in range(len(df)):\n",
    "        item_x = df.iloc[index1, 0]\n",
    "        value_x = df.iloc[index1, 1]\n",
    "        status_x = df.iloc[index1, 2]\n",
    "\n",
    "        if (isinstance(status_x, (int, float)) or str(status_x).isdigit() or status_x == 'Good'):\n",
    "            if value_x == 0:\n",
    "                total_shoppers += 1\n",
    "                current_list = item_x\n",
    "                current_data = [(item_x, value_x)]\n",
    "                data[current_list] = current_data\n",
    "            else:\n",
    "                current_data.append((item_x, value_x))\n",
    "                data[current_list] = current_data\n",
    "\n",
    "        distances = defaultdict(list)\n",
    "\n",
    "        for key, item_list in data.items():\n",
    "            for i in range(len(item_list)):\n",
    "                for j in range(i + 1, len(item_list)):\n",
    "                    item1_name, item1_data = item_list[i]\n",
    "                    item2_name, item2_data = item_list[j]\n",
    "                    distances_key = \"<>\".join(sorted([item1_name, item2_name]))\n",
    "\n",
    "                    weight = 1 / (j - i + 1)\n",
    "\n",
    "                    distance = abs(float(item1_data) - float(item2_data)) * weight\n",
    "                    distances[distances_key].append((distance, i, j))\n",
    "\n",
    "        threshold = 0.5  # Adjust this value as needed\n",
    "        pruned_distances = {}\n",
    "\n",
    "        for key, value in distances.items():\n",
    "            if len(value) > 0:\n",
    "                weighted_distances = [distance for distance, _, _ in value]\n",
    "                max_weight = max([1 / (j - i + 1) for _, i, j in value])\n",
    "                average_distance = sum(weighted_distances) / len(weighted_distances)\n",
    "\n",
    "                if max_weight > 0 and average_distance / max_weight >= threshold:\n",
    "                    pruned_distances[key] = average_distance\n",
    "\n",
    "        sorted_pruned_distances = dict(sorted(pruned_distances.items()))\n",
    "        timegap_dict = defaultdict(list)\n",
    "\n",
    "        for key, value in sorted_pruned_distances.items():\n",
    "            item1, item2 = key.split('<>')\n",
    "            pair = (item1, item2)\n",
    "            timegap_dict[pair] = [value]\n",
    "\n",
    "    return timegap_dict, total_shoppers\n",
    "\n",
    "def silhoutte_score(timegap_dict):\n",
    "    max_clusters = min(len(timegap_dict), 100)\n",
    "    max_iterations_without_improvement = 5\n",
    "    current_score = -1 \n",
    "    best_score = -1\n",
    "    k_optimal = None\n",
    "\n",
    "    k = 20\n",
    "    silhouette_scores = []\n",
    "    k_values = [] \n",
    "    \n",
    "    while True:\n",
    "        if k > max_clusters:\n",
    "            break\n",
    "        \n",
    "        if best_score > current_score:\n",
    "            max_iterations_without_improvement -= 1\n",
    "\n",
    "        if max_iterations_without_improvement == 0:\n",
    "            break\n",
    "\n",
    "        _, linkage_matrix = perform_hierarchical_clustering(timegap_dict, k)\n",
    "        cluster_labels = assign_clusters(linkage_matrix, k)\n",
    "        \n",
    "        timegaps = [timegap for timegaps in timegap_dict.values() for timegap in timegaps]\n",
    "        \n",
    "        silhouette_avg = silhouette_score(np.array(timegaps).reshape(-1, 1), cluster_labels)\n",
    "        silhouette_scores.append(silhouette_avg)\n",
    "        k_values.append(k)\n",
    "\n",
    "        if silhouette_avg > best_score:\n",
    "            best_score = silhouette_avg\n",
    "            k_optimal = k\n",
    "            max_iterations_without_improvement = 5\n",
    "\n",
    "        current_score = silhouette_avg\n",
    "\n",
    "        k += 1\n",
    "\n",
    "    if k_optimal is not None:\n",
    "        plt.figure(figsize=(8, 6))\n",
    "        plt.plot(k_values, silhouette_scores, marker='o')\n",
    "        plt.xlabel('Number of Clusters')\n",
    "        plt.ylabel('Silhouette Score')\n",
    "        plt.title('Silhouette Scores for Different Numbers of Clusters')\n",
    "        plt.grid()\n",
    "        plt.show()\n",
    "\n",
    "    return k_optimal\n",
    "\n",
    "def scree_plot(timegap_dict):\n",
    "    timestamps = []\n",
    "    item_to_index = {}\n",
    "    index = 0\n",
    "\n",
    "    for pair, timegaps in timegap_dict.items():\n",
    "        item_x, item_x_plus_1 = pair\n",
    "\n",
    "        if item_x not in item_to_index:\n",
    "            item_to_index[item_x] = index\n",
    "            index += 1\n",
    "        if item_x_plus_1 not in item_to_index:\n",
    "            item_to_index[item_x_plus_1] = index\n",
    "            index += 1\n",
    "\n",
    "        timestamps.extend(timegaps)\n",
    "\n",
    "    item_indices = [item_to_index[item] for pair in timegap_dict.keys() for item in pair]\n",
    "    distances = np.array(timestamps).reshape(-1, 1)\n",
    "    \n",
    "    y_values = []\n",
    "    for k in range(2, min(30, len(distances) + 1)):\n",
    "        hierarchical = AgglomerativeClustering(n_clusters=k, linkage='ward', compute_distances=True).fit(distances)\n",
    "        y_values.append(hierarchical.distances_)\n",
    "    \n",
    "    x = np.arange(2, min(30, len(distances) + 1)) \n",
    "\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.title('Scree Plot')\n",
    "    plt.xlabel('No. of Clusters (k)')\n",
    "    plt.ylabel('Distance between clusters')\n",
    "    plt.plot(x, [np.mean(y) for y in y_values], marker='o')\n",
    "\n",
    "    curvature = np.diff(y_values, 2)\n",
    "    k_optimal = np.argmax(curvature) + 2\n",
    "    \n",
    "    # Ensure k_optimal is within the range of available values\n",
    "    if k_optimal >= 2 and k_optimal < len(y_values):\n",
    "        plt.scatter(k_optimal, np.mean(y_values[k_optimal - 2]), c='red', label=f'Optimal k ({k_optimal})', marker='x')\n",
    "    \n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "    return k_optimal\n",
    "\n",
    "\n",
    "def perform_hierarchical_clustering(timegap_dict, num_clusters):\n",
    "    timestamps = []\n",
    "    item_to_index = {}\n",
    "    index = 0\n",
    "\n",
    "    for pair, timegaps in timegap_dict.items():\n",
    "        item_x, item_x_plus_1 = pair\n",
    "\n",
    "        if item_x not in item_to_index:\n",
    "            item_to_index[item_x] = index\n",
    "            index += 1\n",
    "        if item_x_plus_1 not in item_to_index:\n",
    "            item_to_index[item_x_plus_1] = index\n",
    "            index += 1\n",
    "\n",
    "        timestamps.extend(timegaps)\n",
    "\n",
    "    item_indices = [item_to_index[item] for pair in timegap_dict.keys() for item in pair]\n",
    "\n",
    "    distances = np.array(timestamps).reshape(-1, 1)\n",
    "    \n",
    "    hierarchical = AgglomerativeClustering(n_clusters=num_clusters, linkage='ward')\n",
    "    cluster_labels = hierarchical.fit_predict(distances)\n",
    "    linkage_matrix = hierarchy.linkage(distances, 'ward')\n",
    "\n",
    "    unique_item_clusters = [cluster_labels[item_indices[i]] for i in range(len(item_indices))]\n",
    "\n",
    "    return cluster_labels, linkage_matrix\n",
    "\n",
    "def assign_clusters(linkage_matrix, num_clusters):\n",
    "    cluster_labels = hierarchy.cut_tree(linkage_matrix, n_clusters=num_clusters)\n",
    "    return cluster_labels.reshape(-1)\n",
    "\n",
    "def plot_dendrogram(linkage_matrix):\n",
    "    hierarchy.dendrogram(linkage_matrix)\n",
    "\n",
    "    plt.xlabel('Data points')\n",
    "    plt.ylabel('Distance')\n",
    "    plt.title('Hierarchical Clustering Dendrogram')\n",
    "    plt.show()\n",
    "\n",
    "def items_graph(timegap_dict, items_in_csv):\n",
    "    G = nx.Graph()\n",
    "    G.add_nodes_from(items_in_csv)\n",
    "\n",
    "    edge_labels = {}\n",
    "    for pair, timegaps in timegap_dict.items():\n",
    "        item_x, item_x_plus_1 = pair\n",
    "        avg = sum(timegaps) / len(timegaps)\n",
    "        \n",
    "        if avg != 0 or G.has_edge(item_x, item_x_plus_1):\n",
    "            G.add_edge(item_x, item_x_plus_1, weight=avg)\n",
    "            edge_labels[(item_x, item_x_plus_1)] = f'{avg:.2f}'\n",
    "\n",
    "    isolated_nodes = [node for node in G.nodes() if G.degree[node] == 0]\n",
    "    G.remove_nodes_from(isolated_nodes)\n",
    "\n",
    "    seed = 42\n",
    "    pos = nx.spring_layout(G, k=1.5, iterations=500, seed=seed)\n",
    "    fig, ax = plt.subplots()\n",
    "\n",
    "    nx.draw(G, pos, with_labels=False, node_color='red', node_size=6, font_size=1, width=0.1, alpha=1, ax=ax)\n",
    "    #edge_labels = nx.draw_networkx_edge_labels(G, pos, edge_labels=edge_labels, font_size=8)\n",
    "    canvas = FigureCanvasTkAgg(fig, master=right_frame)\n",
    "    canvas.draw()\n",
    "    canvas.get_tk_widget().pack(side='top', fill='both', expand=1)\n",
    "\n",
    "def clustered_items_graph(timegap_dict, items_in_csv, cluster_labels, frame):\n",
    "    G = nx.Graph()\n",
    "    G.add_nodes_from(items_in_csv)\n",
    "\n",
    "    for pair, timegaps in timegap_dict.items():\n",
    "        item_x, item_x_plus_1 = pair\n",
    "        avg = sum(timegaps) / len(timegaps)\n",
    "        \n",
    "        if avg != 0 or G.has_edge(item_x, item_x_plus_1):\n",
    "            G.add_edge(item_x, item_x_plus_1, weight=avg)\n",
    "\n",
    "    isolated_nodes = [node for node in G.nodes() if G.degree[node] == 0]\n",
    "    G.remove_nodes_from(isolated_nodes)\n",
    "\n",
    "    seed = 42\n",
    "    pos = nx.spring_layout(G, k=1.5, iterations=500, seed=seed)\n",
    "    fig, ax = plt.subplots()\n",
    "\n",
    "    node_to_cluster = dict(zip(items_in_csv, cluster_labels))\n",
    "    colormap = cm.rainbow\n",
    "    node_colors = [colormap(node_to_cluster[node] / max(cluster_labels)) for node in G.nodes()]\n",
    "    \n",
    "    nx.draw(G, pos, with_labels=False, node_color=node_colors, node_size=6, font_size=-1, width=0.1, alpha=1, ax=ax)\n",
    "    canvas = FigureCanvasTkAgg(fig, master=frame)\n",
    "    canvas.draw()\n",
    "    canvas.get_tk_widget().pack(side='top', fill='both', expand=1)\n",
    "\n",
    "\n",
    "# Create GUI\n",
    "root = Tk()\n",
    "root.title(\"Graph Visualization\")\n",
    "\n",
    "# Create a frame for the main layout\n",
    "main_frame = Frame(root)\n",
    "main_frame.pack(fill='both', expand=True)\n",
    "\n",
    "# Create a frame for the left column (text frames)\n",
    "left_frame = Frame(main_frame)\n",
    "left_frame.pack(side='left', padx=10, pady=10)\n",
    "\n",
    "# Create text widgets and scrollbars for the left column\n",
    "item_list_text = Text(left_frame, height=15, width=80)\n",
    "item_list_text.insert('end', \"List of Items:\\n\")\n",
    "item_list_text.config(state='disabled')\n",
    "item_list_text.pack(side='top')\n",
    "item_list_scrollbar = Scrollbar(left_frame, command=item_list_text.yview)\n",
    "item_list_text['yscrollcommand'] = item_list_scrollbar.set\n",
    "\n",
    "timegap_text = Text(left_frame, height=15, width=80)\n",
    "timegap_text.insert('end', \"Normalized Timegaps:\\n\")\n",
    "timegap_text.config(state='disabled')\n",
    "timegap_text.pack(side='top')\n",
    "timegap_scrollbar = Scrollbar(left_frame, command=timegap_text.yview)\n",
    "timegap_text['yscrollcommand'] = timegap_scrollbar.set\n",
    "\n",
    "dataset_info_text = Text(left_frame, height=15, width=80)\n",
    "dataset_info_text.insert('end', \"Dataset Information:\\n\")\n",
    "dataset_info_text.config(state='disabled')\n",
    "dataset_info_text.pack(side='top')\n",
    "dataset_info_scrollbar = Scrollbar(left_frame, command=dataset_info_text.yview)\n",
    "dataset_info_text['yscrollcommand'] = dataset_info_scrollbar.set\n",
    "\n",
    "clustered_data_text = Text(left_frame, height=15, width=80)\n",
    "clustered_data_text.insert('end', \"Clustered Data:\\n\")\n",
    "clustered_data_text.config(state='disabled')\n",
    "clustered_data_text.pack(side='top')\n",
    "clustered_data_scrollbar = Scrollbar(left_frame, command=clustered_data_text.yview)\n",
    "clustered_data_text['yscrollcommand'] = clustered_data_scrollbar.set\n",
    "\n",
    "# Create a button for processing the CSV\n",
    "process_button = Button(left_frame, text=\"Process CSV and Visualize Graph\", command=process_csv)\n",
    "plt.close('all')\n",
    "\n",
    "# Pack all the widgets in the left column\n",
    "timegap_text.pack(side='top', fill='both', expand=True)\n",
    "#timegap_scrollbar.pack(side='right', fill='y')\n",
    "dataset_info_text.pack(side='top', fill='both', expand=True)\n",
    "#dataset_info_scrollbar.pack(side='right', fill='y')\n",
    "clustered_data_text.pack(side='top', fill='both', expand=True)\n",
    "#clustered_data_scrollbar.pack(side='right', fill='y')\n",
    "process_button.pack(side='top', padx=10, pady=10)\n",
    "\n",
    "# Create a frame for the right column (plots)\n",
    "right_frame = Frame(main_frame)\n",
    "right_frame.pack(side='right', padx=10, pady=10, fill='both', expand=True)\n",
    "\n",
    "root.mainloop()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
